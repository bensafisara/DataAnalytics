{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#2.1 Classement"
      ],
      "metadata": {
        "id": "-67_i6Dx-V7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ouvrez les données d'apprentissage et de test à l'aide de la bibliothèque pandas. Combien y\n",
        "a-t-il d'attributs dans ces \n",
        "chers ? Quels sont leurs types ? Quelle est la variable à prédire ?\n",
        "Les classes sont-elles équilibrées dans les \n",
        "chiers ? Y a-t-il beaucoup de valeurs manquantes\n",
        "dans les données ? Comment ces valeurs sont-elles représentées dans le \n",
        "cher ?"
      ],
      "metadata": {
        "id": "L1ZEmB7OMQRe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "KcnFByvuuNZO",
        "outputId": "9750ad20-5c9c-4d2c-ad43-097e31b96fae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age         workclass  fnlwgt  education  education-num  \\\n",
            "0   39         State-gov   77516  Bachelors             13   \n",
            "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
            "2   38           Private  215646    HS-grad              9   \n",
            "3   53           Private  234721       11th              7   \n",
            "4   28           Private  338409  Bachelors             13   \n",
            "\n",
            "       marital-status         occupation   relationship   race     sex  \\\n",
            "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
            "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
            "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
            "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
            "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
            "\n",
            "   capital-gain  capital-loss  hours-per-week native-country  class  \n",
            "0          2174             0              40  United-States  <=50K  \n",
            "1             0             0              13  United-States  <=50K  \n",
            "2             0             0              40  United-States  <=50K  \n",
            "3             0             0              40  United-States  <=50K  \n",
            "4             0             0              40           Cuba  <=50K  \n",
            "(32561, 15)\n",
            "age                int64\n",
            "workclass         object\n",
            "fnlwgt             int64\n",
            "education         object\n",
            "education-num      int64\n",
            "marital-status    object\n",
            "occupation        object\n",
            "relationship      object\n",
            "race              object\n",
            "sex               object\n",
            "capital-gain       int64\n",
            "capital-loss       int64\n",
            "hours-per-week     int64\n",
            "native-country    object\n",
            "class             object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLes types de Variables\\nage                int64\\nworkclass         object\\nfnlwgt             int64\\neducation         object\\neducation-num      int64\\nmarital-status    object\\noccupation        object\\nrelationship      object\\nrace              object\\nsex               object\\ncapital-gain       int64\\ncapital-loss       int64\\nhours-per-week     int64\\nnative-country    object\\nclass             object\\ndtype: object\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#read input text and put data inside a data frame\n",
        "AdultTrain  = pd.read_csv('/content/drive/MyDrive/TP2DataAnalytics/TP2/AdultEarnings/adult.train.csv')\n",
        "\n",
        "print(AdultTrain.head())\n",
        "print(AdultTrain.shape)\n",
        "print(AdultTrain.dtypes)\n",
        "'''\n",
        "Les types de Variables\n",
        "age                int64\n",
        "workclass         object\n",
        "fnlwgt             int64\n",
        "education         object\n",
        "education-num      int64\n",
        "marital-status    object\n",
        "occupation        object\n",
        "relationship      object\n",
        "race              object\n",
        "sex               object\n",
        "capital-gain       int64\n",
        "capital-loss       int64\n",
        "hours-per-week     int64\n",
        "native-country    object\n",
        "class             object\n",
        "dtype: object\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AdultTest  = pd.read_csv('/content/drive/MyDrive/TP2DataAnalytics/TP2/AdultEarnings/adult.test.csv')\n",
        "\n",
        "print(AdultTest.head())\n",
        "print(AdultTest.shape)\n",
        "print(AdultTest.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU0Wu5-hPrwq",
        "outputId": "5d9e0171-e0b5-41de-f25e-d3d8b7d0a30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
            "0   25    Private  226802          11th              7       Never-married   \n",
            "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
            "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
            "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
            "4   18          ?  103497  Some-college             10       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
            "1    Farming-fishing      Husband  White    Male             0             0   \n",
            "2    Protective-serv      Husband  White    Male             0             0   \n",
            "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
            "4                  ?    Own-child  White  Female             0             0   \n",
            "\n",
            "   hours-per-week native-country  class  \n",
            "0              40  United-States  <=50K  \n",
            "1              50  United-States  <=50K  \n",
            "2              40  United-States   >50K  \n",
            "3              40  United-States   >50K  \n",
            "4              30  United-States  <=50K  \n",
            "(16281, 15)\n",
            "age                int64\n",
            "workclass         object\n",
            "fnlwgt             int64\n",
            "education         object\n",
            "education-num      int64\n",
            "marital-status    object\n",
            "occupation        object\n",
            "relationship      object\n",
            "race              object\n",
            "sex               object\n",
            "capital-gain       int64\n",
            "capital-loss       int64\n",
            "hours-per-week     int64\n",
            "native-country    object\n",
            "class             object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#la class a prédir est 'class'"
      ],
      "metadata": {
        "id": "zB2RcvMveOsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Il y'a des valeurs manquantes dans la data car ils sont exprimé en ? \n",
        "#il y'a 4262 dans le train \n",
        "AdultTrain.isin(['?']).sum(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_enUlSAf5XM",
        "outputId": "5b083c5a-4bd3-47e8-bbfa-f5b5f1f72c38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                  0\n",
              "workclass         1836\n",
              "fnlwgt               0\n",
              "education            0\n",
              "education-num        0\n",
              "marital-status       0\n",
              "occupation        1843\n",
              "relationship         0\n",
              "race                 0\n",
              "sex                  0\n",
              "capital-gain         0\n",
              "capital-loss         0\n",
              "hours-per-week       0\n",
              "native-country     583\n",
              "class                0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AdultTest.isin(['?']).sum(axis=0)\n",
        "#il y' a 2203 valeurs manquantes dans le test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SSU94E_gvLQ",
        "outputId": "50c52729-7afb-4e60-da7f-f016db5caddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                 0\n",
              "workclass         963\n",
              "fnlwgt              0\n",
              "education           0\n",
              "education-num       0\n",
              "marital-status      0\n",
              "occupation        966\n",
              "relationship        0\n",
              "race                0\n",
              "sex                 0\n",
              "capital-gain        0\n",
              "capital-loss        0\n",
              "hours-per-week      0\n",
              "native-country    274\n",
              "class               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Train :  Les classes ne sont pas équilibrés\n",
        "\n",
        "\n",
        "    <=50K    12435\n",
        "    >50K      7841\n",
        "\n",
        "  Proportion \n",
        "    All = 32561\n",
        "    <=50K    24720/All = 0.75 => 75% sont inférieure a 50k\n",
        "    >50K    32561/All = 0.24 => 24% sont supérieure a 50k\n",
        "'''\n",
        "\n",
        "AdultTrain['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzNAtEYoaokw",
        "outputId": "9693f072-babc-4103-fc48-1bc8fa857e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<=50K    24720\n",
              ">50K      7841\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "AdultTest['class'].value_counts()\n",
        "\n",
        "'''\n",
        "TEST : Les classes ne sont pas équilibrés\n",
        "\n",
        " \n",
        "    <=50K    12435\n",
        "    >50K      3846\n",
        "\n",
        "  Proportion \n",
        "    All = 16281\n",
        "    <=50K    12435/All = 0.76 => 70% sont inférieure a 50k\n",
        "    >50K    3846/All = 0.236 => 23% sont supérieure a 50k\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "-o5vHEpuT33Y",
        "outputId": "0765a312-c91a-4c70-eb21-c0fd04ab61c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTEST : Les classes ne sont pas équilibrés\\n\\n \\n    <=50K    12435\\n    >50K      3846\\n\\n  Proportion \\n    All = 16281\\n    <=50K    12435/All = 0.76 => 70% sont inférieure a 50k\\n    >50K    3846/All = 0.236 => 23% sont supérieure a 50k\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dummy classifier"
      ],
      "metadata": {
        "id": "LvXnya11F6kR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il s'agit d'un modèle de classification qui fait des prédictions sans essayer de trouver des modèles pattern dans les données.\n",
        "Le modèle par défaut examine essentiellement l'étiquette la plus fréquente \"most frequent\" dans l'ensemble de données de formation et effectue des prédictions en fonction de cette étiquette tout simplement.\n",
        "\n",
        "Généralement ce dernier est utiliser comme model de références, pour comparer les autres models.\n",
        "Le dummy certe peut donner dans notre cas une très bonne accuracy car nous avons des données déséquilibrés, mais une très bonne accuracy ne signifie pas que le model fait un bon travail.\n"
      ],
      "metadata": {
        "id": "4c_QZMekd8pM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Numerical TRANSFORMATION PART WITH StandarScaler"
      ],
      "metadata": {
        "id": "Ks0-IRbdEggi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN\n",
        "from sklearn.impute import SimpleImputer\n",
        "#Les colonne numérique dans le train et test n'ont pas de valeurs manquantes\n",
        "\n",
        "# Replace missing values by mean and scale numeric values\n",
        "AdultTrainNUMERIQ = AdultTrain.select_dtypes(include='number')\n",
        "#AdultTrainNUMERIQ = AdultTrain[['age', 'fnlwgt' , 'education-num' , 'capital-gain' , 'capital-loss' ,'hours-per-week']]\n",
        "AdultTrainNUMERIQ.replace('?',np.NaN,inplace=True)\n",
        "imp=SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
        "AdultTrainNUMERIQ=pd.DataFrame(imp.fit_transform(AdultTrainNUMERIQ))\n",
        "\n",
        "#on a besoin d'applique ce filtre car dans certaine column on a des outliers alors on  a besoin de remmetre les donées sur la même échelle\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler()\n",
        "AdultTrainNUMERIQ = scaler.fit_transform(AdultTrainNUMERIQ)\n",
        "\n",
        "print(AdultTrainNUMERIQ)\n",
        "X_train1 = AdultTrainNUMERIQ\n",
        "y_train1= AdultTrain['class']\n",
        "\n",
        "\n",
        "print(\"******************************************************\")\n",
        "\n",
        "#TEST\n",
        "from sklearn.impute import SimpleImputer\n",
        "#Les colonne numérique dans le train et test n'ont pas de valeurs manquantes\n",
        "\n",
        "# Replace missing values by mean and scale numeric values\n",
        "AdultTestNUMERIQ = AdultTest.select_dtypes(include='number')\n",
        "AdultTestNUMERIQ.replace('?',np.NaN,inplace=True)\n",
        "imp1=SimpleImputer(missing_values=np.NaN, strategy='mean')\n",
        "AdultTestNUMERIQ=pd.DataFrame(imp1.fit_transform(AdultTestNUMERIQ))\n",
        "#on a besoin d'applique ce filtre car dans certaine column on a des outliers alors on  a besoin de remmetre les données sur la même échelle\n",
        "from sklearn import preprocessing\n",
        "scaler = preprocessing.StandardScaler()\n",
        "AdultTestNUMERIQ = scaler.fit_transform(AdultTestNUMERIQ)\n",
        "print(AdultTestNUMERIQ)\n",
        "X_test1 = AdultTestNUMERIQ\n",
        "y_test1 = AdultTest['class']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VzFCEWhjHTl",
        "outputId": "55a5f303-cb78-45ab-f1f8-4260ba2c7717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.03067056 -1.06361075  1.13473876  0.1484529  -0.21665953 -0.03542945]\n",
            " [ 0.83710898 -1.008707    1.13473876 -0.14592048 -0.21665953 -2.22215312]\n",
            " [-0.04264203  0.2450785  -0.42005962 -0.14592048 -0.21665953 -0.03542945]\n",
            " ...\n",
            " [ 1.42360965 -0.35877741 -0.42005962 -0.14592048 -0.21665953 -0.03542945]\n",
            " [-1.21564337  0.11095988 -0.42005962 -0.14592048 -0.21665953 -1.65522476]\n",
            " [ 0.98373415  0.92989258 -0.42005962  1.88842434 -0.21665953 -0.03542945]]\n",
            "******************************************************\n",
            "[[-0.99412926  0.35347399 -1.19686359 -0.14266185 -0.21806206 -0.03143184]\n",
            " [-0.05541716 -0.94239062 -0.41788553 -0.14266185 -0.21806206  0.7699177 ]\n",
            " [-0.77750339  1.39544986  0.75058156 -0.14266185 -0.21806206 -0.03143184]\n",
            " ...\n",
            " [-0.05541716  1.75522095  1.14007059 -0.14266185 -0.21806206  0.7699177 ]\n",
            " [ 0.37783458 -0.99842039  1.14007059  0.57664374 -0.21806206 -0.03143184]\n",
            " [-0.27204303 -0.0689392   1.14007059 -0.14266185 -0.21806206  1.57126723]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5244: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5244: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS VALIDATION With numerical attributes\n"
      ],
      "metadata": {
        "id": "KiFNMoIDFqpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import metrics\n",
        "\n",
        "print(\"CROSS VALIDATION With numerical attributes\")\n",
        "def accuracy_score(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        scores = cross_val_score(clf, X, y, cv=5)\n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "def confusion_matrix(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        predicted = cross_val_predict(clf, X, y, cv=5) \n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f\" % metrics.accuracy_score(y, predicted))\n",
        "        print(metrics.confusion_matrix(y, predicted))\n",
        "\n",
        "\n",
        "dummycl = DummyClassifier(strategy=\"most_frequent\")\n",
        "gmb = GaussianNB()\n",
        "dectree = tree.DecisionTreeClassifier()\n",
        "rdforest = RandomForestClassifier()\n",
        "logreg = LogisticRegression(solver=\"liblinear\")\n",
        "svc = svm.SVC(gamma='scale')\n",
        "\n",
        "lst_classif = [dummycl, gmb, dectree, rdforest, logreg, svc]\n",
        "lst_classif_names = ['Dummy', 'Naive Bayes', 'Decision tree', 'Random Forest', 'Logistic regression', 'SVM']\n",
        "\n",
        "accuracy_score(lst_classif,lst_classif_names,X_train1,y_train1)\n",
        "confusion_matrix(lst_classif,lst_classif_names,X_train1,y_train1)\n",
        "\n",
        "'''\n",
        "le dummy \n",
        "[[24720     0]\n",
        " [ 7841     0]]\n",
        "\n",
        " a toujourd classer toutes les instance dans la classes 0 c a d income<=50k \n",
        " on voit bient que 24720 classé correctement or 7841 qui était de la class 1 on était classé comme class 0\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "oOnwuLW21Ku1",
        "outputId": "18d88af7-947f-4353-e8bd-87413d5e3eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VALIDATION With numerical attributes\n",
            "Accuracy of Dummy classifier on cross-validation: 0.76 (+/- 0.00)\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.80 (+/- 0.01)\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.77 (+/- 0.01)\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.81 (+/- 0.01)\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.82 (+/- 0.01)\n",
            "Accuracy of SVM classifier on cross-validation: 0.82 (+/- 0.01)\n",
            "Accuracy of Dummy classifier on cross-validation: 0.76\n",
            "[[24720     0]\n",
            " [ 7841     0]]\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.80\n",
            "[[23493  1227]\n",
            " [ 5411  2430]]\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.77\n",
            "[[20908  3812]\n",
            " [ 3623  4218]]\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.81\n",
            "[[22266  2454]\n",
            " [ 3851  3990]]\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.82\n",
            "[[23452  1268]\n",
            " [ 4750  3091]]\n",
            "Accuracy of SVM classifier on cross-validation: 0.82\n",
            "[[23895   825]\n",
            " [ 4912  2929]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nle dummy \\n[[24720     0]\\n [ 7841     0]]\\n\\n a toujourd classer toutes les instance dans la classes 0 c a d income<=50k \\n on voit bient que 24720 classé correctement or 7841 qui était de la class 1 on était classé comme class 0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CATEGORICAL TRANSFORMATION PART WITH OneHotEncoder"
      ],
      "metadata": {
        "id": "Z2TNqJUIANlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Train\n",
        "\n",
        "# Replace missing values by mode and discretize categorical values\n",
        "AdultTrainCATEGO = AdultTrain.select_dtypes(exclude='number').drop('class',axis=1)\n",
        "\n",
        "AdultTrainCATEGO.replace('?',np.NaN,inplace=True)\n",
        "imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n",
        "AdultTrainCATEGO=pd.DataFrame(imputer.fit_transform(AdultTrainCATEGO))\n",
        "\n",
        "'''\n",
        "AdultTrainCATEGO = pd.get_dummies(AdultTrainCATEGO)\n",
        "AdultTrainCATEGO.head()\n",
        "print(AdultTrainCATEGO)\n",
        "'''\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "AdultTrainCATEGO=AdultTrainCATEGO.apply(lambda col: le.fit_transform(col))\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "#One-hot-encode the categorical columns.\n",
        "#Unfortunately outputs an array instead of dataframe.\n",
        "array_hot_encoded = ohe.fit_transform(AdultTrainCATEGO).toarray()\n",
        "\n",
        "#Convert it to df\n",
        "AdultTrainCATEGO = pd.DataFrame(array_hot_encoded, index=AdultTrain.index)\n",
        "\n",
        "\n",
        "X_train2 = AdultTrainCATEGO\n",
        "y_train2= AdultTrain['class']\n",
        "\n",
        "\n",
        "print(AdultTrainCATEGO)\n",
        "\n",
        "\n",
        "\n",
        "print(\"******************************************************\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Test\n",
        "\n",
        "# Replace missing values by mean and discretize categorical values\n",
        "AdultTestCATEGO = AdultTest.select_dtypes(exclude='number').drop('class',axis=1)\n",
        "AdultTestCATEGO.replace('?',np.NaN,inplace=True)\n",
        "imputer = SimpleImputer(missing_values=np.NaN, strategy='most_frequent')\n",
        "AdultTestCATEGO=pd.DataFrame(imputer.fit_transform(AdultTestCATEGO))\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "AdultTestCATEGO=AdultTestCATEGO.apply(lambda col: le.fit_transform(col))\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "\n",
        "#One-hot-encode the categorical columns.\n",
        "#Unfortunately outputs an array instead of dataframe.\n",
        "array_hot_encoded = ohe.fit_transform(AdultTestCATEGO).toarray()\n",
        "\n",
        "#Convert it to df\n",
        "AdultTestCATEGO = pd.DataFrame(array_hot_encoded, index=AdultTest.index)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODejAzDIGgwX",
        "outputId": "6c5f4d66-1d51-428a-b1ca-879f187c196c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0    1    2    3    4    5    6    7    8    9   ...   89   90   91  \\\n",
            "0      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "1      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "2      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "3      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0  0.0  0.0   \n",
            "4      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "32556  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "32557  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "32558  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "32559  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "32560  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
            "\n",
            "        92   93   94   95   96   97   98  \n",
            "0      0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "1      0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "2      0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "3      0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
            "...    ...  ...  ...  ...  ...  ...  ...  \n",
            "32556  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "32557  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "32558  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "32559  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "32560  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
            "\n",
            "[32561 rows x 99 columns]\n",
            "******************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROSS VALIDATION With Categorical attributes"
      ],
      "metadata": {
        "id": "4KV9X7luGHxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CROSS VALIDATION With Categorical attributes\")\n",
        "def accuracy_score(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        scores = cross_val_score(clf, X, y, cv=5)\n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "def confusion_matrix(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        predicted = cross_val_predict(clf, X, y, cv=5) \n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f\" % metrics.accuracy_score(y, predicted))\n",
        "        print(metrics.confusion_matrix(y, predicted))\n",
        "\n",
        "\n",
        "dummycl = DummyClassifier(strategy=\"most_frequent\")\n",
        "gmb = GaussianNB()\n",
        "dectree = tree.DecisionTreeClassifier()\n",
        "rdforest = RandomForestClassifier()\n",
        "logreg = LogisticRegression(solver=\"liblinear\")\n",
        "svc = svm.SVC(gamma='scale')\n",
        "\n",
        "lst_classif = [dummycl, gmb, dectree, rdforest, logreg, svc]\n",
        "lst_classif_names = ['Dummy', 'Naive Bayes', 'Decision tree', 'Random Forest', 'Logistic regression', 'SVM']\n",
        "\n",
        "accuracy_score(lst_classif,lst_classif_names,X_train2,y_train2)\n",
        "confusion_matrix(lst_classif,lst_classif_names,X_train2,y_train2)\n"
      ],
      "metadata": {
        "id": "2Ao06fkSAeQl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "385b8bbe-17b1-4f3b-b0fb-afe8cbbaf6f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CROSS VALIDATION With Categorical attributes\n",
            "Accuracy of Dummy classifier on cross-validation: 0.76 (+/- 0.00)\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.51 (+/- 0.05)\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.82 (+/- 0.00)\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.82 (+/- 0.00)\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.83 (+/- 0.01)\n",
            "Accuracy of SVM classifier on cross-validation: 0.83 (+/- 0.01)\n",
            "Accuracy of Dummy classifier on cross-validation: 0.76\n",
            "[[24720     0]\n",
            " [ 7841     0]]\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.51\n",
            "[[ 9033 15687]\n",
            " [  397  7444]]\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.82\n",
            "[[22373  2347]\n",
            " [ 3589  4252]]\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.82\n",
            "[[22539  2181]\n",
            " [ 3522  4319]]\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.83\n",
            "[[22908  1812]\n",
            " [ 3725  4116]]\n",
            "Accuracy of SVM classifier on cross-validation: 0.83\n",
            "[[22909  1811]\n",
            " [ 3729  4112]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CROSS VALIDATION AVEC les attributs numériques et catégoriels"
      ],
      "metadata": {
        "id": "E9AepBk1H-Bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-learn fournit une classe ColumnTransformer qui enverra des colonnes spécifiques à un transformateur spécifique, ce qui facilite l'ajustement d'un modèle prédictif unique sur un ensemble de données qui combine les deux types de variables.\n",
        "\n",
        "Ici nous allons cree un pipeline"
      ],
      "metadata": {
        "id": "xd6b-IVpjw5p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, notre objectif est de prédire le revenu qui peut être soit 0 soit 1 classification binaire (moins de 50 000 ou plus de 50 000) et nous voulons identifier une relation entre notre résultat (revenu) et les autres caractéristiques indépendantes (éducation, classe ouvrière, sexe, etc.). "
      ],
      "metadata": {
        "id": "j4rOr9vWlosc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"TRAIN AND TEST THE MODEL with numeriq columns\")\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import tree\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "dataTrain=AdultTrain\n",
        "target_name = \"class\"\n",
        "target = dataTrain[target_name]\n",
        "dataTrain = dataTrain.drop(columns=[target_name])\n",
        "dataTrain.replace('?',np.NaN,inplace=True)\n",
        "\n",
        "\n",
        "##################################################\n",
        "\n",
        "dataTest=AdultTest\n",
        "target_name = \"class\"\n",
        "targetest = dataTest[target_name]\n",
        "dataTest = dataTest.drop(columns=[target_name])\n",
        "dataTest.replace('?',np.NaN,inplace=True)"
      ],
      "metadata": {
        "id": "kYg6RkcXZGFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7630cc92-1f97-47ac-9b53-cbc3b4e1f094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN AND TEST THE MODEL with numeriq columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols=['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week','workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "[dataTrain.columns.get_loc(c) for c in cols if c in dataTrain]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCMI6_YiPYUN",
        "outputId": "e298984d-8ef5-4bd4-93c2-7b3733555884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2, 4, 10, 11, 12, 1, 3, 5, 6, 7, 8, 9, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline,make_pipeline\n",
        "#https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html"
      ],
      "metadata": {
        "id": "XFK-b6EeGFRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "numeric_features = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
        "numeric_transformer = Pipeline(\n",
        "    steps=[(\"imputer\", SimpleImputer(missing_values=np.NaN, strategy='mean')), (\"scaler\",  StandardScaler())]\n",
        ")\n",
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "# NB :I had to use A sparse=false because by default it s true, and this on is not matrix containg a lot of zeros, could skip it\n",
        "#it was the problem of my errors for a long moment \n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[('imputer2',SimpleImputer(missing_values=np.NaN, strategy='most_frequent')), ('ohe',OneHotEncoder(sparse=False,handle_unknown='ignore')) ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features),\n",
        "    ]\n",
        ")\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "\n",
        "def accuracy_score_PIPELINE(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        model = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", clf)]\n",
        ")\n",
        "        scores = cross_val_score(model,  X, y, cv=5)\n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "def confusion_matrix_PIPELINE(lst_classif,lst_classif_names,X,y):\n",
        "    for clf,name_clf in zip(lst_classif,lst_classif_names):\n",
        "        model = Pipeline(\n",
        "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", clf)]\n",
        ")\n",
        "        predicted = cross_val_predict(model, X, y, cv=5) \n",
        "        print(\"Accuracy of \"+name_clf+\" classifier on cross-validation: %0.2f\" % metrics.accuracy_score(y, predicted))\n",
        "        print(metrics.confusion_matrix(y, predicted))\n",
        "\n",
        "\n",
        "accuracy_score_PIPELINE(lst_classif,lst_classif_names,dataTrain, target)\n",
        "confusion_matrix_PIPELINE(lst_classif,lst_classif_names,dataTrain, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ozdW3iaU0WE",
        "outputId": "23465441-1577-4737-c99c-bb174ab942bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Dummy classifier on cross-validation: 0.76 (+/- 0.00)\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.54 (+/- 0.03)\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.81 (+/- 0.01)\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.85 (+/- 0.01)\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.85 (+/- 0.01)\n",
            "Accuracy of SVM classifier on cross-validation: 0.86 (+/- 0.01)\n",
            "Accuracy of Dummy classifier on cross-validation: 0.76\n",
            "[[24720     0]\n",
            " [ 7841     0]]\n",
            "Accuracy of Naive Bayes classifier on cross-validation: 0.54\n",
            "[[10145 14575]\n",
            " [  388  7453]]\n",
            "Accuracy of Decision tree classifier on cross-validation: 0.81\n",
            "[[21614  3106]\n",
            " [ 2940  4901]]\n",
            "Accuracy of Random Forest classifier on cross-validation: 0.85\n",
            "[[22921  1799]\n",
            " [ 2969  4872]]\n",
            "Accuracy of Logistic regression classifier on cross-validation: 0.85\n",
            "[[23029  1691]\n",
            " [ 3151  4690]]\n",
            "Accuracy of SVM classifier on cross-validation: 0.86\n",
            "[[23257  1463]\n",
            " [ 3225  4616]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sélectionnez le meilleur modèle testé lors des con\n",
        "gurations précédentes et apprenez-le sur\n",
        "l'ensemble des données d'apprentissage. Quelle est la performance mesurée avec ce modèle sur\n",
        "le corpus de test ? Quelle est la classe pour laquelle la prédiction fait le plus d'erreurs ?\n"
      ],
      "metadata": {
        "id": "VF3qxqOEy-9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrainer le model et tester \n",
        "clf = svm.SVC(gamma='scale')\n",
        "name_clf = \"Support vector machine\"\n",
        "\n",
        "model = Pipeline(\n",
        "steps=[(\"preprocessor\", preprocessor), (\"classifier\", clf)])\n",
        "model.fit(dataTrain, target )\n",
        "# TODO\n",
        "y_pred =  model.predict(dataTest)\n",
        "\n",
        "print('Accuracy of '+name_clf+' classifier on training set: {:.2f}'\n",
        "      .format(model.score(dataTrain, target)))\n",
        "print('Accuracy of '+name_clf+' classifier on test set: {:.2f}'\n",
        "  .format(model.score(dataTest, targetest)))\n",
        "print(confusion_matrix(targetest, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG98CAWyOA25",
        "outputId": "3756f34b-58f2-4182-af7d-80e99d8402d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Support vector machine classifier on training set: 0.87\n",
            "Accuracy of Support vector machine classifier on test set: 0.86\n",
            "[[11720   715]\n",
            " [ 1594  2252]]\n"
          ]
        }
      ]
    }
  ]
}